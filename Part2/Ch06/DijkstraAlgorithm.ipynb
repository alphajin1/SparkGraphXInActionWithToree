{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@5dbcf890"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dijkstra: [VD](g: org.apache.spark.graphx.Graph[VD,Double], origin: org.apache.spark.graphx.VertexId)org.apache.spark.graphx.Graph[(VD, Double),Double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "import org.apache.spark.graphx._\n",
    "def dijkstra[VD](g:Graph[VD,Double], origin:VertexId) = {\n",
    "    // 초기화\n",
    "    var distGraph = g.mapVertices(\n",
    "        (vertexId, props) => (false, if (vertexId == origin) 0 else Double.MaxValue)\n",
    "    )\n",
    "    \n",
    "    // Iteration\n",
    "    for (i <- 1L to g.vertices.count-1) { \n",
    "        // dist가 제일 작은 VertexId 찾기\n",
    "        val currentVertexId = distGraph.vertices.filter(!_._2._1).fold( (0L, (false, Double.MaxValue)) )((a,b) => if (a._2._2 < b._2._2) a else b)._1\n",
    "        \n",
    "        // aggregateMessages 의 return은 Vertices\n",
    "        val newDistances = distGraph.aggregateMessages[Double]( \n",
    "                triplet => // Map Function\n",
    "                    if (triplet.srcId == currentVertexId)\n",
    "                        // Send Message to destination vertex\n",
    "                        triplet.sendToDst(triplet.srcAttr._2 + triplet.attr), \n",
    "                (a,b) => math.min(a,b) // reduce phrase\n",
    "            )\n",
    "        \n",
    "        // outerJoinVertices 의 return은 Graph\n",
    "        distGraph = distGraph.outerJoinVertices(newDistances)(\n",
    "            (vertexId, props, newDist) => \n",
    "                // return (Boolean, NewDist)\n",
    "                (props._1 || vertexId == currentVertexId, math.min(props._2, newDist.getOrElse(Double.MaxValue)))\n",
    "            )\n",
    "    }\n",
    "    \n",
    "    // property and dist\n",
    "    g.outerJoinVertices(distGraph.vertices)((vertexId, props, dist) => (props, dist.getOrElse( (false,Double.MaxValue) )._2 ) )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myVertices = ParallelCollectionRDD[1728] at makeRDD at <console>:85\n",
       "myEdges = ParallelCollectionRDD[1729] at makeRDD at <console>:92\n",
       "myGraph = org.apache.spark.graphx.impl.GraphImpl@71464fe\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Array((A,0.0), (B,7.0), (C,15.0), (D,5.0), (E,14.0), (F,11.0), (G,22.0))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val myVertices = sc.makeRDD(\n",
    "    Array(\n",
    "        (1L, \"A\"), (2L, \"B\"), (3L, \"C\"), \n",
    "        (4L, \"D\"), (5L, \"E\"), (6L, \"F\"), \n",
    "        (7L, \"G\"))\n",
    "    )\n",
    "\n",
    "val myEdges = sc.makeRDD(\n",
    "    Array(\n",
    "        Edge(1L, 2L, 7.0), Edge(1L, 4L, 5.0), Edge(2L, 3L, 8.0), \n",
    "        Edge(2L, 4L, 9.0), Edge(2L, 5L, 7.0), Edge(3L, 5L, 5.0), \n",
    "        Edge(4L, 5L, 15.0), Edge(4L, 6L, 6.0), Edge(5L, 6L, 8.0), \n",
    "        Edge(5L, 7L, 9.0), Edge(6L, 7L, 11.0))\n",
    "    )\n",
    "\n",
    "val myGraph = Graph(myVertices, myEdges)\n",
    "dijkstra(myGraph, 1L).vertices.map(_._2).collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG Phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distGraph = org.apache.spark.graphx.impl.GraphImpl@26155e0a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Array((1,(false,0.0)), (2,(false,1.7976931348623157E308)), (3,(false,1.7976931348623157E308)), (4,(false,1.7976931348623157E308)), (5,(false,1.7976931348623157E308)), (6,(false,1.7976931348623157E308)), (7,(false,1.7976931348623157E308)))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var distGraph = myGraph.mapVertices(\n",
    "    (vertexId, props) => (false, if (vertexId == 1L) 0 else Double.MaxValue)\n",
    ")\n",
    "\n",
    "distGraph.vertices.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "currentVertexId = 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val currentVertexId = distGraph.vertices.filter(!_._2._1).fold( (0L, (false, Double.MaxValue)) )((a,b) => if (a._2._2 < b._2._2) a else b)._1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((1,(false,0.0)), (2,(false,1.7976931348623157E308)), (3,(false,1.7976931348623157E308)), (4,(false,1.7976931348623157E308)), (5,(false,1.7976931348623157E308)), (6,(false,1.7976931348623157E308)), (7,(false,1.7976931348623157E308)))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distGraph.vertices.filter(!_._2._1).collect // 아직 방문하지 않은 Vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newDistances = VertexRDDImpl[1855] at RDD at VertexRDD.scala:57\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Array((2,7.0), (4,5.0))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val newDistances = distGraph.aggregateMessages[Double]( \n",
    "                triplet => // Map Function\n",
    "                    if (triplet.srcId == currentVertexId)\n",
    "                        // Send Message to destination vertex\n",
    "                        triplet.sendToDst(triplet.srcAttr._2 + triplet.attr), \n",
    "                (a,b) => math.min(a,b) // reduce phrase\n",
    "            )\n",
    "\n",
    "newDistances.collect // VertexRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((1,(A,0.0)), (2,(B,7.0)), (3,(C,15.0)), (4,(D,5.0)), (5,(E,14.0)), (6,(F,11.0)), (7,(G,22.0)))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dijkstra(myGraph, 1L).vertices.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
